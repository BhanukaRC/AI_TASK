# Example .env file for Pathfinder Rules Interrogation System

# OpenAI API key (optional, enables vector search and moderation)
OPENAI_API_KEY=

# Groq API key (required for main LLM answer generation)
GROQ_API_KEY=

# Path to the cache file (default: ./cache/pdf_cache.json)
CACHE_PATH=./cache/pdf_cache.json

# Path to the resources (PDFs) folder (default: ./resources)
RESOURCES_FOLDER=./resources

# Model to use for Groq (default: llama-3.3-70b-versatile)
GROQ_MODEL=llama-3.3-70b-versatile

# (Optional) Response validation threshold (default: 5)
RESPONSE_VALIDATION_THRESHOLD=5

# (Optional) Retry count for answer validation (default: 3)
RETRY_COUNT=3

# (Optional) Disable Groq question relevance check (default: false)
DISABLE_GROQ_QUESTION_RELAVANCE_CHECK=false